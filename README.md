# :pushpin: TOYCONN
>ë™ë„¤ê¸°ë°˜ ì¤‘ê³  ì¥ë‚œê° ëŒ€ì—¬ ì„œë¹„ìŠ¤ </br>
> ë°ëª¨ì‚¬ì´íŠ¸ ë§í¬: http://localhost:8081/ToyConn_pro/main.jsp

</br>

## 1. ì œì‘ ê¸°ê°„ & ì°¸ì—¬ ì¸ì›
- 2023ë…„ 11ì›” 14ì¼ ~ 11ì›” 30ì¼
- íŒ€ í”„ë¡œì íŠ¸

</br>

## 2. ì‚¬ìš© ê¸°ìˆ 
#### `DB ë° Crawling`
  - MySQL Oracle 11
  - Python
  - Selenium
  - BeautifulSoup
</br>

## 3. ERD - DB í…Œì´ë¸” ì„¤ê³„
<img src = "https://github.com/2023-SMHRD-IS-BigData2/R2L3_team/blob/main/ToyConn_pro/src/main/webapp/images/erd.png">


## 4. í•µì‹¬ ê¸°ëŠ¥
- ì¤‘ê³ ì¥ë‚œê°: ì¤‘ê³ ì‚¬ì´íŠ¸ì— ì¿¨ë¡¤ë§ -> ë°ì´í„° ìˆ˜ì§‘ -> excelíŒŒì•Œìœ¼ë¡œ ìˆ˜ì¶œ -> ë°ì´í„° ì²˜ë¦¬ -> oracleë°ì´í„°ë°°ì´ìŠ¤ SQLë¬¸ í™œìš©í•˜ê³  ì €ì¥
- í”„ë¦¬ë¯¸ì—„: ìŠ¤ë§ˆíŠ¸ë„¤ì´ë²„ìŠ¤í„°ì— ì¿¨ë¡¤ë§ -> ë°ì´í„° ìˆ˜ì§‘ -> excelíŒŒì•Œìœ¼ë¡œ ìˆ˜ì¶œ -> ë°ì´í„° ì²˜ë¦¬ -> oracleë°ì´í„°ë°°ì´ìŠ¤ SQLë¬¸ í™œìš©í•˜ê³  ì €ì¥
- ì•„ë˜ì— ì½”ë“œ ì…ë‹ˆë‹¤.
  ### ìƒí’ˆëª…, ìƒí’ˆê°’ ë°ì´í„° ìˆ˜ì§‘ ğŸŒ¼
  #### library import
from selenium import webdriver as wb <br>
from bs4 import BeautifulSoup as bs
import requests as req
import os
import pandas as pd
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import time
from urllib.request import urlretrieve 
#### get url
url = "https://www.daangn.com/search/%EC%9E%A5%EB%82%9C%EA%B0%90/"
head_option = {
'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'}
res= req.get(url, headers = head_option)
html = bs(res.text,'html')
#### run driver
driver = wb.Chrome();
driver.get(url);
#### ì „ì²´ íŒŒì´ì§€ í™”ë©´ ë³´ê¸°
last_height = driver.execute_script("return document.body.scrollWidth")
while(True):
    body = driver.find_element(By.TAG_NAME,'body')
    body.send_keys(Keys.END)
    time.sleep(1)
    current_height=driver.execute_script("return document.body.scrollWidth")
    #3. í˜ì´ì§€ ë†’ì´ì— ë³€í™”ê°€ ì—†ë‹¤ë©´ ë°˜ë³µë¬¸ ë¹ ì ¸ë‚˜ì˜¤ê¸°
    if current_height == last_height:
        break
    last_height = current_height
    print(last_height, current_height)
### ìƒí’ˆëª…, ìƒí’ˆê°’ ë°ì´í„° ìˆ˜ì§‘
names = []
prices = []
length = len(driver.find_elements(By.CLASS_NAME,"article-title"))
for i in range (length):
    name = driver.find_elements(By.CLASS_NAME, "article-title")[i].text
    price = driver.find_elements(By.CLASS_NAME, "article-price")[i].text
    names.append(name)
    prices.append(price)
#### ë°ì´í„° í”„ë ˆì„ ë„£ê¸°
data = pd.DataFrame(data = zip(names,prices),columns = ['Items','Price'])
#### exportíŒŒì¼
data.to_excel('ë‹¹ê·¼_ì¥ë‚œê°23.11.13.03.xlsx',index = False)
### ì´ë¯¸ì§€ ìˆ˜ì§‘ â˜˜
imgs = driver.find_elements(By.CSS_SELECTOR,'div.card-photo>img')
data = []
for i in range(len(imgs)):
    data.append(urlretrieve(imgs[i].get_attribute('src'),f"C:\\Users\\dd\\AppData\\Local\\Temp\\Carrot\\Carrot{i}.jpg"))
### ìƒí’ˆí‘œí˜„ ìˆ˜ì§‘ğŸŒ¸ğŸŒ¸
#### link ìˆ˜ì§‘
detail_link = []
for i in range(len(driver.find_elements(By.CSS_SELECTOR,'a.flea-market-article-link'))):
    detail_link.append(driver.find_elements(By.CSS_SELECTOR,'a.flea-market-article-link')[i].get_attribute('href'))
detail_link
#### ìƒí’ˆí´í˜„ ìˆ˜ì§‘
details =[]
for i in range(len(detail_link)):
    driver = wb.Chrome()
    driver.get(detail_link[i])
    detail = driver.find_element(By.CSS_SELECTOR,'div#article-detail').text.strip('\n')
    details.append(detail)

#### ë°ì´í„° í”„ë ˆì„ ë„£ê¸°
data = pd.DataFrame(data = zip(range(1,100),details),columns = [no','detail'])
#### exportíŒŒì¼
data.to_excel('ë‹¹ê·¼_ì¥ë‚œê°_detail23.11.13.03.xlsx',index = False)
    



